{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0efa805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (non-exhaustive)\n",
    "import numpy as np    \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "# from tensorflow.keras.layers import RandomFlip, RandomZoom, RandomRotation, Rescaling\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# .python must be added for tensorflow versions 1.xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5ae331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories definition\n",
    "train_path = \"C:/Users/user/Desktop/Chest Xray Classifier/dataset/train\"\n",
    "test_path = \"C:/Users/user/Desktop/Chest Xray Classifier/dataset/test\"\n",
    "val_path = \"C:/Users/user/Desktop/Chest Xray Classifier/dataset/val\"\n",
    "\n",
    "# Basic parameters (image dimension and batch size)\n",
    "batch_size = 16\n",
    "img_height = 500\n",
    "img_width = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7763d0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4192 files belonging to 2 classes.\n",
      "Found 624 files belonging to 2 classes.\n",
      "Found 1040 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "\n",
    "# Load data\n",
    "\n",
    "train = tf.keras.utils.image_dataset_from_directory(train_path,\n",
    "                                                    image_size=(img_height, img_width),\n",
    "                                                    color_mode='grayscale',\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "test = tf.keras.utils.image_dataset_from_directory(test_path,\n",
    "                                                   image_size=(img_height, img_width),\n",
    "                                                   color_mode='grayscale',\n",
    "                                                   shuffle=False, \n",
    "                                                   label_mode='binary',\n",
    "                                                   batch_size=batch_size)\n",
    "\n",
    "valid = tf.keras.utils.image_dataset_from_directory(val_path,\n",
    "                                                    image_size=(img_height, img_width),\n",
    "                                                    color_mode='grayscale',\n",
    "                                                    label_mode='binary',\n",
    "                                                    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76e4a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture (Input->CNN->Flat->ANN->Output)\n",
    "cnn = Sequential()\n",
    "\n",
    "# Preprocessing (data augmentation) layers\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomRotation(0.2),    \n",
    "    ])\n",
    "cnn.add(data_augmentation)\n",
    "\n",
    "# Convolution and Pooling Layers\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten \n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Fully-connected Neural Network Layers\n",
    "cnn.add(Dense(activation='relu', units = 128))\n",
    "cnn.add(Dense(activation='relu', units = 64))\n",
    "cnn.add(Dense(activation='relu', units = 64))\n",
    "cnn.add(Dense(activation='sigmoid', units = 1))\n",
    "\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Regularization callbacks\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3) # Patience: no. of epochs to run after monitored parameter stops changing\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.3, min_lr=0.00001)\n",
    "callbacks_ls = [early, learning_rate_reduction] \n",
    "\n",
    "# Class weights for unbalanced datasets\n",
    "# Assign higher weights to the minority class, reduce bias towards majority class\n",
    "# Calculate proportion, invert it as a counter-bias\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# weights = compute_class_weight('balanced', np.unique(train.class_names))\n",
    "# class_weight_val = dict(zip(np.unique(train.class_names), weights))\n",
    "# #print(class_weight_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model (run this cell to train)\n",
    "# cnn.fit(train, epochs=30, validation_data=valid, class_weight=class_weight_val, callbacks=callbacks_ls)\n",
    "cnn.fit(train, epochs=30, validation_data=valid, callbacks=callbacks_ls)\n",
    "# Training metric visualization\n",
    "pd.DataFrame(cnn.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "test_model = cnn.evaluate(test)\n",
    "test_accu = test_model[1] * 100\n",
    "print('Test Accuracy: ', test_accu, '%')\n",
    "\n",
    "# Convert prediction output to binary classes (Sigmoid: 0 < output < 1)\n",
    "prediction = cnn.predict(test, verbose=1)\n",
    "prediction_bin = prediction.copy()\n",
    "\n",
    "for i in prediction_bin:\n",
    "    if (i <= 0.5):\n",
    "        prediction_bin[i] = 0\n",
    "    elif (i > 0.5):\n",
    "        prediction_bin[i] = 1\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "con_mat = pd.DataFrame(data=confusion_matrix(test.classes, prediction_bin, labels=[0, 1]),\n",
    "                       index=[\"Actual Normal\", \"Actual Pneumonia\"],\n",
    "                       columns=[\"Predicted Normal\", \"Predicted Pneumonia\"])\n",
    "print(classification_report(y_true=test.classes, y_pred=prediction_bin, target_names=['NORMAL','PNEUMONIA']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
